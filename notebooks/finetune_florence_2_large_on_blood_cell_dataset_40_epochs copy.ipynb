{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVmYbqqUSlCH"
      },
      "source": [
        "# Fine-tuning Florence-2 on Blood Cell Object Detection Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z16cfHRE8yi8"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vp9cS2-gXbn",
        "outputId": "85a70762-1fe8-4482-dc7f-552d817b27c7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqd30Ndg9dbt"
      },
      "source": [
        "### Configure your API keys\n",
        "\n",
        "To fine-tune Florence-2, you need to provide your HuggingFace Token and Roboflow API key."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n32nrwCeAEYP"
      },
      "source": [
        "### Select the runtime\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `L4 GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMmBuhiiC2mX",
        "outputId": "e0c91cc2-104c-4826-a4e8-3ddff36488f5"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOshHQM3Ebq5"
      },
      "source": [
        "### Download example data\n",
        "\n",
        "**NOTE:** Feel free to replace our example image with your own photo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3ZhBCTPEnEO",
        "outputId": "99bd166b-dda7-4b85-bf22-4824ab643a5a"
      },
      "outputs": [],
      "source": [
        "image_url=\"https://huggingface.co/spaces/dwb2023/omniscience/resolve/main/examples/BloodImage_00038_jpg.rf.1b0ce1635e11b3b49302de527c86bb02.jpg\"\n",
        "\n",
        "# get image_url and write it to /content/source_img.jpg\n",
        "!wget -O /content/source_img.jpg $image_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbglpBOOFCHm"
      },
      "outputs": [],
      "source": [
        "EXAMPLE_IMAGE_PATH = \"/content/source_img.jpg\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM4QlaUfCFsv"
      },
      "source": [
        "## Download and configure the model\n",
        "\n",
        " Let's download the model checkpoint and configure it so that you can fine-tune it later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6b1dvjgYXOD",
        "outputId": "e62ff6f2-4820-443b-88ab-9d0f9041ab48"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers flash_attn timm einops peft\n",
        "!pip install -q roboflow git+https://github.com/roboflow/supervision.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMd6tb4sSh9G"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import torch\n",
        "import html\n",
        "import base64\n",
        "import itertools\n",
        "\n",
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "from google.colab import userdata\n",
        "from IPython.core.display import display, HTML\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoProcessor,\n",
        "    get_scheduler\n",
        ")\n",
        "from tqdm import tqdm\n",
        "from typing import List, Dict, Any, Tuple, Generator\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from PIL import Image\n",
        "from roboflow import Roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flp13B-8Myjf"
      },
      "source": [
        "Load the model using `AutoModelForCausalLM` and the processor using `AutoProcessor` classes from the transformers library. Note that you need to pass `trust_remote_code` as `True` since this model is not a standard transformers model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqDWEWDcaSxN"
      },
      "outputs": [],
      "source": [
        "CHECKPOINT = \"microsoft/Florence-2-large-ft\"\n",
        "# REVISION = 'refs/pr/6'\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(CHECKPOINT, trust_remote_code=True).to(DEVICE)\n",
        "processor = AutoProcessor.from_pretrained(CHECKPOINT, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf1GlvvQFec-"
      },
      "source": [
        "## Run inference with pre-trained Florence-2 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "ReAKWNxAFmv1",
        "outputId": "5df8fd92-c2b2-4549-a45b-6d83dd8c3835"
      },
      "outputs": [],
      "source": [
        "# @title Example object detection inference\n",
        "\n",
        "image = Image.open(EXAMPLE_IMAGE_PATH)\n",
        "task = \"<OD>\"\n",
        "text = \"<OD>\"\n",
        "\n",
        "inputs = processor(text=text, images=image, return_tensors=\"pt\").to(DEVICE)\n",
        "generated_ids = model.generate(\n",
        "    input_ids=inputs[\"input_ids\"],\n",
        "    pixel_values=inputs[\"pixel_values\"],\n",
        "    max_new_tokens=256,\n",
        "    num_beams=3\n",
        ")\n",
        "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
        "response = processor.post_process_generation(generated_text, task=task, image_size=(image.width, image.height))\n",
        "detections = sv.Detections.from_lmm(sv.LMM.FLORENCE_2, response, resolution_wh=image.size)\n",
        "\n",
        "bounding_box_annotator = sv.BoundingBoxAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
        "label_annotator = sv.LabelAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
        "\n",
        "image = bounding_box_annotator.annotate(image, detections)\n",
        "image = label_annotator.annotate(image, detections)\n",
        "image.thumbnail((600, 600))\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQetrQM7Jziy"
      },
      "source": [
        "## Fine-tune Florence-2 on custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw7D6ZYzAs9a"
      },
      "source": [
        "### Download dataset from Roboflow Universe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1IlyjYmBCxX",
        "outputId": "a0aefa84-f828-49b0-b5e5-463edbb22ec9"
      },
      "outputs": [],
      "source": [
        "ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
        "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "\n",
        "project = rf.workspace(\"roboflow-100\").project(\"bccd-ouzjz\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"florence2-od\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiLclUnKTrLE",
        "outputId": "e8655a6a-aedd-409c-9a80-c2aec8f438dc"
      },
      "outputs": [],
      "source": [
        "!head -n 5 {dataset.location}/train/annotations.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dExvJNFkxymc"
      },
      "outputs": [],
      "source": [
        "# @title Define `DetectionsDataset` class\n",
        "\n",
        "class JSONLDataset:\n",
        "    def __init__(self, jsonl_file_path: str, image_directory_path: str):\n",
        "        self.jsonl_file_path = jsonl_file_path\n",
        "        self.image_directory_path = image_directory_path\n",
        "        self.entries = self._load_entries()\n",
        "\n",
        "    def _load_entries(self) -> List[Dict[str, Any]]:\n",
        "        entries = []\n",
        "        with open(self.jsonl_file_path, 'r') as file:\n",
        "            for line in file:\n",
        "                data = json.loads(line)\n",
        "                entries.append(data)\n",
        "        return entries\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.entries)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[Image.Image, Dict[str, Any]]:\n",
        "        if idx < 0 or idx >= len(self.entries):\n",
        "            raise IndexError(\"Index out of range\")\n",
        "\n",
        "        entry = self.entries[idx]\n",
        "        image_path = os.path.join(self.image_directory_path, entry['image'])\n",
        "        try:\n",
        "            image = Image.open(image_path)\n",
        "            return (image, entry)\n",
        "        except FileNotFoundError:\n",
        "            raise FileNotFoundError(f\"Image file {image_path} not found.\")\n",
        "\n",
        "\n",
        "class DetectionDataset(Dataset):\n",
        "    def __init__(self, jsonl_file_path: str, image_directory_path: str):\n",
        "        self.dataset = JSONLDataset(jsonl_file_path, image_directory_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, data = self.dataset[idx]\n",
        "        prefix = data['prefix']\n",
        "        suffix = data['suffix']\n",
        "        return prefix, suffix, image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilMb0ivGdt9l"
      },
      "outputs": [],
      "source": [
        "# @title Initiate `DetectionsDataset` and `DataLoader` for train and validation subsets\n",
        "\n",
        "BATCH_SIZE = 6\n",
        "NUM_WORKERS = 0\n",
        "\n",
        "def collate_fn(batch):\n",
        "    questions, answers, images = zip(*batch)\n",
        "    inputs = processor(text=list(questions), images=list(images), return_tensors=\"pt\", padding=True).to(DEVICE)\n",
        "    return inputs, answers\n",
        "\n",
        "train_dataset = DetectionDataset(\n",
        "    jsonl_file_path = f\"{dataset.location}/train/annotations.jsonl\",\n",
        "    image_directory_path = f\"{dataset.location}/train/\"\n",
        ")\n",
        "val_dataset = DetectionDataset(\n",
        "    jsonl_file_path = f\"{dataset.location}/valid/annotations.jsonl\",\n",
        "    image_directory_path = f\"{dataset.location}/valid/\"\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, num_workers=NUM_WORKERS, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, num_workers=NUM_WORKERS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZYoV_EjOo5A",
        "outputId": "7ab4f8a8-e9be-4ac0-b370-003fc32a6332"
      },
      "outputs": [],
      "source": [
        "def analyze_suffix_length(dataset, processor, num_samples=100):\n",
        "    max_suffix_length = 0\n",
        "    max_suffix_token_length = 0\n",
        "\n",
        "    for i in range(min(num_samples, len(dataset))):\n",
        "        _, suffix, _ = dataset[i]\n",
        "\n",
        "        # Get token length using the processor\n",
        "        tokens = processor.tokenizer(suffix, return_tensors=\"pt\").input_ids[0]\n",
        "        token_length = len(tokens)\n",
        "\n",
        "        # Update max lengths\n",
        "        max_suffix_length = max(max_suffix_length, len(suffix))\n",
        "        max_suffix_token_length = max(max_suffix_token_length, token_length)\n",
        "\n",
        "    print(f\"Max suffix length (characters): {max_suffix_length}\")\n",
        "    print(f\"Max suffix length (tokens): {max_suffix_token_length}\")\n",
        "    print(f\"Current max_new_tokens: 1024\")\n",
        "\n",
        "    if max_suffix_token_length > 1024:\n",
        "        print(\"Warning: max_new_tokens may be too small for some suffixes\")\n",
        "    else:\n",
        "        print(\"Current max_new_tokens should be sufficient\")\n",
        "\n",
        "# Use the function\n",
        "analyze_suffix_length(train_dataset, processor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmPJOXCzB-29",
        "outputId": "cbee50a7-4e06-402c-f2d0-92e0c3a4eac8"
      },
      "outputs": [],
      "source": [
        "# @title Setup LoRA Florence-2 model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=8,\n",
        "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"linear\", \"Conv2d\", \"lm_head\", \"fc2\"],\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    inference_mode=False,\n",
        "    use_rslora=True,\n",
        "    init_lora_weights=\"gaussian\",\n",
        ")\n",
        "\n",
        "peft_model = get_peft_model(model, config)\n",
        "peft_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V9BcVQMycgq"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i9LEEXRwN9cX",
        "outputId": "6b9e4cd9-7852-4826-ca4c-4f2c79aa470e"
      },
      "outputs": [],
      "source": [
        "# @title Run inference with pre-trained Florence-2 model on validation dataset\n",
        "\n",
        "def render_inline(image: Image.Image, resize=(128, 128)):\n",
        "    \"\"\"Convert image into inline html.\"\"\"\n",
        "    image.resize(resize)\n",
        "    with io.BytesIO() as buffer:\n",
        "        image.save(buffer, format='jpeg')\n",
        "        image_b64 = str(base64.b64encode(buffer.getvalue()), \"utf-8\")\n",
        "        return f\"data:image/jpeg;base64,{image_b64}\"\n",
        "\n",
        "\n",
        "def render_example(image: Image.Image, response):\n",
        "    try:\n",
        "        detections = sv.Detections.from_lmm(sv.LMM.FLORENCE_2, response, resolution_wh=image.size)\n",
        "        image = sv.BoundingBoxAnnotator(color_lookup=sv.ColorLookup.INDEX).annotate(image.copy(), detections)\n",
        "        image = sv.LabelAnnotator(color_lookup=sv.ColorLookup.INDEX).annotate(image, detections)\n",
        "    except:\n",
        "        print('failed to redner model response')\n",
        "    return f\"\"\"\n",
        "<div style=\"display: inline-flex; align-items: center; justify-content: center;\">\n",
        "    <img style=\"width:256px; height:256px;\" src=\"{render_inline(image, resize=(128, 128))}\" />\n",
        "    <p style=\"width:512px; margin:10px; font-size:small;\">{html.escape(json.dumps(response))}</p>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def render_inference_results(model, dataset: DetectionDataset, count: int):\n",
        "    html_out = \"\"\n",
        "    count = min(count, len(dataset))\n",
        "    for i in range(count):\n",
        "        image, data = dataset.dataset[i]\n",
        "        prefix = data['prefix']\n",
        "        suffix = data['suffix']\n",
        "        inputs = processor(text=prefix, images=image, return_tensors=\"pt\").to(DEVICE)\n",
        "        generated_ids = model.generate(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            pixel_values=inputs[\"pixel_values\"],\n",
        "            max_new_tokens=256,\n",
        "            num_beams=3\n",
        "        )\n",
        "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
        "        answer = processor.post_process_generation(generated_text, task='<OD>', image_size=image.size)\n",
        "        html_out += render_example(image, answer)\n",
        "\n",
        "    display(HTML(html_out))\n",
        "\n",
        "render_inference_results(peft_model, val_dataset, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH9JTq_RytE2"
      },
      "source": [
        "## Fine-tune Florence-2 on custom object detection dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC06Mc7jOdpY"
      },
      "outputs": [],
      "source": [
        "# @title Define train loop\n",
        "\n",
        "def train_model(train_loader, val_loader, model, processor, epochs=10, lr=1e-6):\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    num_training_steps = epochs * len(train_loader)\n",
        "    lr_scheduler = get_scheduler(\n",
        "        name=\"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_training_steps,\n",
        "    )\n",
        "\n",
        "    render_inference_results(peft_model, val_loader.dataset, 6)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for inputs, answers in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}/{epochs}\"):\n",
        "\n",
        "            input_ids = inputs[\"input_ids\"]\n",
        "            pixel_values = inputs[\"pixel_values\"]\n",
        "            labels = processor.tokenizer(\n",
        "                text=answers,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=True,\n",
        "                return_token_type_ids=False\n",
        "            ).input_ids.to(DEVICE)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, pixel_values=pixel_values, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            loss.backward(), optimizer.step(), lr_scheduler.step(), optimizer.zero_grad()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        print(f\"Average Training Loss: {avg_train_loss}\")\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, answers in tqdm(val_loader, desc=f\"Validation Epoch {epoch + 1}/{epochs}\"):\n",
        "\n",
        "                input_ids = inputs[\"input_ids\"]\n",
        "                pixel_values = inputs[\"pixel_values\"]\n",
        "                labels = processor.tokenizer(\n",
        "                    text=answers,\n",
        "                    return_tensors=\"pt\",\n",
        "                    padding=True,\n",
        "                    return_token_type_ids=False\n",
        "                ).input_ids.to(DEVICE)\n",
        "\n",
        "                outputs = model(input_ids=input_ids, pixel_values=pixel_values, labels=labels)\n",
        "                loss = outputs.loss\n",
        "\n",
        "                val_loss += loss.item()\n",
        "\n",
        "            avg_val_loss = val_loss / len(val_loader)\n",
        "            print(f\"Average Validation Loss: {avg_val_loss}\")\n",
        "\n",
        "            render_inference_results(peft_model, val_loader.dataset, 6)\n",
        "\n",
        "        output_dir = f\"./model_checkpoints/epoch_{epoch+1}\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        model.save_pretrained(output_dir)\n",
        "        processor.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LZybGHd3fNJ1",
        "outputId": "c1c7be61-c4c5-4994-f3ac-a040f9f22c31"
      },
      "outputs": [],
      "source": [
        "# @title Run train loop\n",
        "\n",
        "%%time\n",
        "\n",
        "EPOCHS = 40\n",
        "LR = 5e-6\n",
        "\n",
        "train_model(train_loader, val_loader, peft_model, processor, epochs=EPOCHS, lr=LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBHMu7WGWpeu"
      },
      "source": [
        "## Fine-tuned model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f1BYeQw3xhl"
      },
      "outputs": [],
      "source": [
        "# @title Collect predictions\n",
        "\n",
        "# Corrected pattern to capture class names correctly\n",
        "PATTERN = r'(RBC|WBC|Platelets)'\n",
        "\n",
        "def extract_classes(dataset: DetectionDataset):\n",
        "    class_set = set()\n",
        "    for i in range(len(dataset.dataset)):\n",
        "        image, data = dataset.dataset[i]\n",
        "        suffix = data[\"suffix\"]\n",
        "        classes = re.findall(PATTERN, suffix)\n",
        "        class_set.update(classes)\n",
        "    return sorted(class_set)\n",
        "\n",
        "CLASSES = extract_classes(train_dataset)\n",
        "\n",
        "targets = []\n",
        "predictions = []\n",
        "\n",
        "for i in range(len(val_dataset.dataset)):\n",
        "    image, data = val_dataset.dataset[i]\n",
        "    prefix = data['prefix']\n",
        "    suffix = data['suffix']\n",
        "\n",
        "    inputs = processor(text=prefix, images=image, return_tensors=\"pt\").to(DEVICE)\n",
        "    generated_ids = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        pixel_values=inputs[\"pixel_values\"],\n",
        "        max_new_tokens=256,\n",
        "        num_beams=3\n",
        "    )\n",
        "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
        "\n",
        "    prediction = processor.post_process_generation(generated_text, task='<OD>', image_size=image.size)\n",
        "    prediction = sv.Detections.from_lmm(sv.LMM.FLORENCE_2, prediction, resolution_wh=image.size)\n",
        "    prediction = prediction[np.isin(prediction['class_name'], CLASSES)]\n",
        "    prediction.class_id = np.array([CLASSES.index(class_name) for class_name in prediction['class_name']])\n",
        "    prediction.confidence = np.ones(len(prediction))\n",
        "\n",
        "    target = processor.post_process_generation(suffix, task='<OD>', image_size=image.size)\n",
        "    target = sv.Detections.from_lmm(sv.LMM.FLORENCE_2, target, resolution_wh=image.size)\n",
        "    target.class_id = np.array([CLASSES.index(class_name) for class_name in target['class_name']])\n",
        "\n",
        "    targets.append(target)\n",
        "    predictions.append(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKECYHh-z95f",
        "outputId": "690ab21b-f5d3-4608-f291-bcf1c941990c"
      },
      "outputs": [],
      "source": [
        "CLASSES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88VnIZ_feHPo",
        "outputId": "9fc48273-24ae-4b3a-a71b-57fdfee2f0c6"
      },
      "outputs": [],
      "source": [
        "# @title Calculate mAP\n",
        "mean_average_precision = sv.MeanAveragePrecision.from_detections(\n",
        "    predictions=predictions,\n",
        "    targets=targets,\n",
        ")\n",
        "\n",
        "print(f\"map50_95: {mean_average_precision.map50_95:.2f}\")\n",
        "print(f\"map50: {mean_average_precision.map50:.2f}\")\n",
        "print(f\"map75: {mean_average_precision.map75:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "85APzNRfe8xp",
        "outputId": "260eb915-49e3-49b1-e215-d7cc6b504526"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import supervision as sv  # Ensure this is the correct library\n",
        "import json\n",
        "\n",
        "# @title Calculate Confusion Matrix\n",
        "confusion_matrix = sv.ConfusionMatrix.from_detections(\n",
        "    predictions=predictions,\n",
        "    targets=targets,\n",
        "    classes=CLASSES\n",
        ")\n",
        "\n",
        "_ = confusion_matrix.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfTi6NmpmiuU",
        "outputId": "8af15af7-da64-40d1-c577-944a7d1b8be6"
      },
      "outputs": [],
      "source": [
        "# Correctly access the matrix attribute\n",
        "conf_matrix_values = confusion_matrix.matrix\n",
        "\n",
        "# Print to check the values are extracted correctly\n",
        "print(\"Confusion Matrix Values:\", conf_matrix_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "w4jbxLsmlO7j",
        "outputId": "1c022a10-ca1b-4f82-e74d-4ae72fa6ce17"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Assuming y_true and y_pred are your ground truth and predicted labels\n",
        "conf_matrix = confusion_matrix(y_true, y_pred, labels=range(len(CLASSES)))\n",
        "\n",
        "# Convert confusion matrix to JSON format\n",
        "def confusion_matrix_to_json(conf_matrix, classes):\n",
        "    conf_matrix_dict = {\n",
        "        \"classes\": classes,\n",
        "        \"matrix\": conf_matrix.tolist()\n",
        "    }\n",
        "    return json.dumps(conf_matrix_dict, indent=4)\n",
        "\n",
        "json_output = confusion_matrix_to_json(conf_matrix, CLASSES)\n",
        "print(json_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rR2naNXzEB0"
      },
      "source": [
        "## Save fine-tuned model on hard drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdbmcv3TcIe8",
        "outputId": "218d993c-414e-4682-86ab-c58db826ad0b"
      },
      "outputs": [],
      "source": [
        "peft_model.save_pretrained(\"/content/florence2-large-ft\")\n",
        "processor.save_pretrained(\"/content/florence2-large-ft/\")\n",
        "!ls -la /content/florence2-large/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "a9289c461dbe4cecb9e691766eecbe37",
            "bf1811c46899427d920af49b20bb8ee2",
            "0e385484fed6499eaf9a563a41623acc",
            "95d542586c2c4726b3ec10ea4eb06011",
            "e8a9f64dc4ad458e83580fc708514e7a",
            "079e0c3428ec4572bcfe845d345f7318",
            "ece7b911ecda44a7ac3bad2f5229b8be",
            "1c18c58c22f94d12b0f61c034ee8dd7a",
            "9118b17e1e9a4949af081f13717a34db",
            "e154937e4db249ca93eeb86652858455",
            "8bfeb74ca14f4f2d8cbf36081f73b7a3",
            "2bdadfa556454c219aa6ebb1ddcf3485",
            "9710de1c4e54496fbc501a9056fd9af1",
            "83742b470564441c93a8a5a88a41d7d7",
            "5c2272cd6d2d417f9f0c6fee95ae3d83",
            "ba460d52106641a8a0168e1610933fe4",
            "f4d85a0a6d9043c1afe1cdab71b0bf75",
            "e5d93b4839f7415fbbb6263f51b0e5e1",
            "62c3411212544a2aadbf4af460bce439",
            "37eff0dac8144865bfc319b1954b2968",
            "e89e8d9b8c364a34a4f2e7981ffeed85",
            "c9a571522381476c9ff997ac776992c3"
          ]
        },
        "id": "fyP9ZW2bf1te",
        "outputId": "80405e7f-6b36-4366-a00c-5d65e4d9e96a"
      },
      "outputs": [],
      "source": [
        "# Push the model to the Hub with your desired name\n",
        "peft_model.push_to_hub(\"dwb2023/florence2-large-bccd-base-ft\")\n",
        "processor.push_to_hub(\"dwb2023/florence2-large-bccd-base-ft\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_DdE_NOfJLG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "079e0c3428ec4572bcfe845d345f7318": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e385484fed6499eaf9a563a41623acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c18c58c22f94d12b0f61c034ee8dd7a",
            "max": 5174,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9118b17e1e9a4949af081f13717a34db",
            "value": 5174
          }
        },
        "1c18c58c22f94d12b0f61c034ee8dd7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bdadfa556454c219aa6ebb1ddcf3485": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9710de1c4e54496fbc501a9056fd9af1",
              "IPY_MODEL_83742b470564441c93a8a5a88a41d7d7",
              "IPY_MODEL_5c2272cd6d2d417f9f0c6fee95ae3d83"
            ],
            "layout": "IPY_MODEL_ba460d52106641a8a0168e1610933fe4"
          }
        },
        "37eff0dac8144865bfc319b1954b2968": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c2272cd6d2d417f9f0c6fee95ae3d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e89e8d9b8c364a34a4f2e7981ffeed85",
            "placeholder": "​",
            "style": "IPY_MODEL_c9a571522381476c9ff997ac776992c3",
            "value": " 16.6M/16.6M [00:01&lt;00:00, 18.1MB/s]"
          }
        },
        "62c3411212544a2aadbf4af460bce439": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83742b470564441c93a8a5a88a41d7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62c3411212544a2aadbf4af460bce439",
            "max": 16582384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37eff0dac8144865bfc319b1954b2968",
            "value": 16582384
          }
        },
        "8bfeb74ca14f4f2d8cbf36081f73b7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9118b17e1e9a4949af081f13717a34db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95d542586c2c4726b3ec10ea4eb06011": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e154937e4db249ca93eeb86652858455",
            "placeholder": "​",
            "style": "IPY_MODEL_8bfeb74ca14f4f2d8cbf36081f73b7a3",
            "value": " 5.17k/5.17k [00:00&lt;00:00, 424kB/s]"
          }
        },
        "9710de1c4e54496fbc501a9056fd9af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4d85a0a6d9043c1afe1cdab71b0bf75",
            "placeholder": "​",
            "style": "IPY_MODEL_e5d93b4839f7415fbbb6263f51b0e5e1",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "a9289c461dbe4cecb9e691766eecbe37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf1811c46899427d920af49b20bb8ee2",
              "IPY_MODEL_0e385484fed6499eaf9a563a41623acc",
              "IPY_MODEL_95d542586c2c4726b3ec10ea4eb06011"
            ],
            "layout": "IPY_MODEL_e8a9f64dc4ad458e83580fc708514e7a"
          }
        },
        "ba460d52106641a8a0168e1610933fe4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf1811c46899427d920af49b20bb8ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_079e0c3428ec4572bcfe845d345f7318",
            "placeholder": "​",
            "style": "IPY_MODEL_ece7b911ecda44a7ac3bad2f5229b8be",
            "value": "README.md: 100%"
          }
        },
        "c9a571522381476c9ff997ac776992c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e154937e4db249ca93eeb86652858455": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5d93b4839f7415fbbb6263f51b0e5e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e89e8d9b8c364a34a4f2e7981ffeed85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a9f64dc4ad458e83580fc708514e7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ece7b911ecda44a7ac3bad2f5229b8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4d85a0a6d9043c1afe1cdab71b0bf75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
